{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of files (participants): 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from typing import List\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Get a list of all xlsx files\n",
    "files = sorted(glob(\"../typedb-schema/CPs exp 2a data/*.xlsx\"))\n",
    "\n",
    "data = {}\n",
    "\n",
    "\n",
    "def change_class_name(class_name: str) -> str:\n",
    "    \"\"\"Change the class name to a more readable format.\n",
    "\n",
    "    Args:\n",
    "        class_name (str): The class name to be changed.\n",
    "\n",
    "    Returns:\n",
    "        str: The changed class name.\n",
    "\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"agents\": \"actor\",\n",
    "        \"objects\": \"object\",\n",
    "        \"actions\": \"action\",\n",
    "        \"locations\": \"location\",\n",
    "    }[class_name]\n",
    "\n",
    "\n",
    "print(f\"number of files (participants): {len(files)}\\n\")\n",
    "# Loop through the list of files and read each file\n",
    "for file in files:\n",
    "    print(f\"processing `{file}` ...\")\n",
    "\n",
    "    participant = file.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "    dataframe = pd.read_excel(file)\n",
    "    dataframe.drop_duplicates(subset=\"name\", keep=\"last\", inplace=True)\n",
    "    # Now you can do something with the data\n",
    "    assert len(dataframe.situation) == len(dataframe.actions)\n",
    "    print(\n",
    "        f\"There are in total of {len(dataframe.situation)} situation-action pairs \"\n",
    "        f\"in the file {file}, \\nparticipant number: {participant}\\n\"\n",
    "    )\n",
    "\n",
    "    situations = []\n",
    "    actions = []\n",
    "    data[participant] = []\n",
    "    for situation, action in zip(dataframe.situation, dataframe.actions):\n",
    "        # Parse HTML content\n",
    "        situation_parsed = []\n",
    "\n",
    "        if isinstance(situation, float) and math.isnan(situation):\n",
    "            situation_parsed = None\n",
    "\n",
    "        else:\n",
    "            soup = BeautifulSoup(situation, \"html.parser\")\n",
    "\n",
    "            # Extract data\n",
    "            for div in soup.find_all(\"div\", class_=\"item\"):\n",
    "                # Extract class and text content\n",
    "\n",
    "                class_name = (\n",
    "                    div.get(\"class\")[1]\n",
    "                    if len(div.get(\"class\")) > 1\n",
    "                    else div.get(\"class\")[0]\n",
    "                )\n",
    "                # Process the text content more carefully to add spaces around buttons\n",
    "                # or special divs\n",
    "                texts = div.find_all(text=True)\n",
    "                text_content = \" \".join(text.strip() for text in texts).strip().lower()\n",
    "                if class_name != \"counters\":  # we don't use this anymore\n",
    "                    situation_parsed.append(\n",
    "                        [change_class_name(class_name), text_content]\n",
    "                    )\n",
    "\n",
    "        situations.append(situation_parsed)\n",
    "\n",
    "        soup = BeautifulSoup(action, \"html.parser\")\n",
    "        action_parsed = {}\n",
    "\n",
    "        # Extract boxes\n",
    "        boxes = soup.find_all(\"div\", class_=\"box box_action\")\n",
    "\n",
    "        for box in boxes:\n",
    "            box_id = box.get(\"id\")\n",
    "            action_parsed[box_id] = []\n",
    "\n",
    "            items = box.find_all(\"div\", class_=\"item\")\n",
    "            for item in items:\n",
    "                class_name = (\n",
    "                    item.get(\"class\")[1]\n",
    "                    if len(item.get(\"class\")) > 1\n",
    "                    else item.get(\"class\")[0]\n",
    "                )\n",
    "                # Process the text content more carefully to add spaces around buttons\n",
    "                # or special divs\n",
    "                texts = item.find_all(text=True)\n",
    "                text_content = \" \".join(text.strip() for text in texts).strip().lower()\n",
    "                if class_name != \"counters\":  # we don't use this anymore\n",
    "                    action_parsed[box_id].append(\n",
    "                        [change_class_name(class_name), text_content]\n",
    "                    )\n",
    "\n",
    "        actions.append(action_parsed)\n",
    "        assert len(situations) == len(actions)\n",
    "        data[participant].append(\n",
    "            {\"situation\": situation_parsed, \"what_we_do\": action_parsed}\n",
    "        )\n",
    "\n",
    "    # data[participant] = list(zip(situations, actions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the data a bit more explainable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_better = {}\n",
    "weird = []\n",
    "participants = sorted(list(data.keys()))\n",
    "\n",
    "for participant_id, data_list in data.items():\n",
    "\n",
    "    data_better[participant_id] = []\n",
    "    for i, data_dict in enumerate(data_list):\n",
    "\n",
    "        human_macro_actions, robot_macro_actions = [], []\n",
    "        for box_id, list_of_tuples in data_dict[\"what_we_do\"].items():\n",
    "            if [\"actor\", \"robot\"] in list_of_tuples:\n",
    "                robot_macro_actions.append(list_of_tuples)\n",
    "            elif [\"actor\", \"human\"] in list_of_tuples:\n",
    "                human_macro_actions.append(list_of_tuples)\n",
    "            else:\n",
    "                weird.append(list_of_tuples)\n",
    "\n",
    "        data_better[participant_id].append(\n",
    "            {\n",
    "                \"situation_graph\": data_dict[\"situation\"],\n",
    "                \"human_action_graph\": human_macro_actions,\n",
    "                \"robot_action_graph\": robot_macro_actions,\n",
    "            }\n",
    "        )\n",
    "data = data_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant_id, list_ in data.items():\n",
    "    print(f\"Participant {participant_id}\")\n",
    "    for i, data_dict in enumerate(list_):\n",
    "        print(f\"Situation {i:02}\")\n",
    "        print(f\"Situation graph: {data_dict['situation_graph']}\")\n",
    "        print(f\"Human action graphs: {data_dict['human_action_graph']}\")\n",
    "        print(f\"Robot action graphs: {data_dict['robot_action_graph']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert the python dict to RDF/Turtle data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def order_types(list_of_type_and_literal: List[List[str]]) -> List[List[str]]:\n",
    "    \"\"\"Order the types and literals in a list of lists.\n",
    "\n",
    "    Args:\n",
    "        list_of_type_and_literal (List[List[str]]): A list of lists containing the types and literals\n",
    "\n",
    "    Returns:\n",
    "        List[List[str]]: A list of lists containing the ordered types and literals\n",
    "\n",
    "    \"\"\"\n",
    "    # Define the order of the types\n",
    "    order = [\"actor\", \"action\", \"object\", \"location\"]\n",
    "\n",
    "    assert all(\n",
    "        x[0] in order for x in list_of_type_and_literal\n",
    "    ), f\"Unknown type: {list_of_type_and_literal}\"\n",
    "\n",
    "    return sorted(list_of_type_and_literal, key=lambda x: order.index(x[0]))\n",
    "\n",
    "\n",
    "def type_and_literal_to_turtle(type_: str, literal: str) -> str:\n",
    "    \"\"\"Convert a type and literal to a Turtle string.\n",
    "\n",
    "    Args:\n",
    "        type_ (str): The type\n",
    "        literal (str): The literal\n",
    "\n",
    "    Returns:\n",
    "        str: The Turtle string\n",
    "\n",
    "    \"\"\"\n",
    "    # literal = f'\"{\", \".join(literal)}\"'\n",
    "    return f'    colearn:{type_}Type \"{literal}\" ;'\n",
    "\n",
    "\n",
    "def is_valid_actions_in_graph(graph: List[List[str]]) -> bool:\n",
    "    \"\"\"Check if the actions in the graph are valid.\n",
    "\n",
    "    Args:\n",
    "        graph (List[List[str]]): A list of lists containing the graph\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the actions are valid, False otherwise\n",
    "\n",
    "    \"\"\"\n",
    "    for action in graph:\n",
    "        if len(action) > 0:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def add_human_or_robot_action_to_turtle(\n",
    "    list_of_actions: list,\n",
    "    participant_id: str,\n",
    "    situation_id: str,\n",
    "    human_or_robot: str,\n",
    ") -> List[str]:\n",
    "\n",
    "    num_actions = len(list_of_actions)\n",
    "    turtle_content = []\n",
    "\n",
    "    actor = \"Human\" if human_or_robot.lower() == \"human\" else \"Robot\"\n",
    "    prefix = \"h\" if human_or_robot.lower() == \"human\" else \"r\"\n",
    "\n",
    "    turtle_content.append(f\"# Define the {actor} actions.\")\n",
    "\n",
    "    for idx_a, action in enumerate(list_of_actions):\n",
    "        action_id = f\"{prefix}{idx_a:02}\"\n",
    "        next_action_id = f\"{prefix}{idx_a+1:02}\"\n",
    "        previous_action_id = f\"{prefix}{idx_a-1:02}\"\n",
    "\n",
    "        turtle_content.append(\n",
    "            f\"colearn:{participant_id}_{situation_id}_{action_id} a colearn:{actor}Action ;\"\n",
    "        )\n",
    "        turtle_content.append(\n",
    "            f'    rdfs:label \"Participant {participant_id}, Situation {situation_id}, {actor}-Action {action_id}\" ;'\n",
    "        )\n",
    "        list_of_type_and_literal = order_types(action)\n",
    "        for type_, literal in list_of_type_and_literal:\n",
    "            turtle_content.append(type_and_literal_to_turtle(type_, literal))\n",
    "\n",
    "        if idx_a == 0 and num_actions > 1:\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:isActionOf colearn:{participant_id}_{situation_id} ;\"\n",
    "            )\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:hasNextAction colearn:{participant_id}_{situation_id}_{next_action_id} .\\n\"\n",
    "            )\n",
    "        elif idx_a == 0 and num_actions == 1:\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:isActionOf colearn:{participant_id}_{situation_id} .\\n\"\n",
    "            )\n",
    "        elif idx_a > 0 and idx_a < num_actions - 1:\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:isActionOf colearn:{participant_id}_{situation_id} ;\"\n",
    "            )\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:hasNextAction colearn:{participant_id}_{situation_id}_{next_action_id} ;\"\n",
    "            )\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:hasPreviousAction colearn:{participant_id}_{situation_id}_{previous_action_id} .\\n\"\n",
    "            )\n",
    "        elif idx_a == num_actions - 1:\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:isActionOf colearn:{participant_id}_{situation_id} ;\"\n",
    "            )\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:hasPreviousAction colearn:{participant_id}_{situation_id}_{previous_action_id} .\\n\"\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown {actor} action for participant {participant_id}, situation {situation_id}, action {action_id}\"\n",
    "            )\n",
    "\n",
    "    return turtle_content\n",
    "\n",
    "\n",
    "def create_turtle(participant_id: str, data: List[dict]) -> List[str]:\n",
    "    \"\"\"Create a Turtle file from the data.\n",
    "\n",
    "    Args:\n",
    "        participant_id (str): The participant ID\n",
    "        data (List[dict]): A list of dictionaries containing the data\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of strings containing the Turtle content\n",
    "\n",
    "    \"\"\"\n",
    "    # Define the header and namespaces\n",
    "    turtle_content = [\n",
    "        \"@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .\",\n",
    "        \"@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\",\n",
    "        \"@prefix owl: <http://www.w3.org/2002/07/owl#> .\",\n",
    "        \"@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\",\n",
    "        \"@prefix colearn: <http://example.org/colearn#> .\",\n",
    "        \"\",\n",
    "        # Define the main participant\n",
    "        f\"# Define a participant\",\n",
    "        f\"colearn:{participant_id} a colearn:Participant ;\",\n",
    "        f'    rdfs:label \"Participant {participant_id}\" .',\n",
    "        f\"\",\n",
    "    ]\n",
    "\n",
    "    for idx_s, situation in enumerate(data):\n",
    "\n",
    "        is_valid_situation = False if situation[\"situation_graph\"] is None else True\n",
    "        is_human_action = is_valid_actions_in_graph(situation[\"human_action_graph\"])\n",
    "        is_robot_action = is_valid_actions_in_graph(situation[\"robot_action_graph\"])\n",
    "\n",
    "        if not is_valid_situation:\n",
    "            continue\n",
    "        if not is_human_action and not is_robot_action:\n",
    "            continue\n",
    "\n",
    "        situation_id = f\"s{idx_s:02}\"\n",
    "        turtle_content.append(f\"# A new situation {participant_id}_{situation_id} starts\")\n",
    "        turtle_content.append(\n",
    "            f\"colearn:{participant_id} colearn:hasSituation colearn:{participant_id}_{situation_id} .\\n\"\n",
    "        )\n",
    "        turtle_content.append(f\"# Define a situation.\")\n",
    "        turtle_content.append(\n",
    "            f\"colearn:{participant_id}_{situation_id} a colearn:Situation ;\"\n",
    "        )\n",
    "        turtle_content.append(\n",
    "            f'    rdfs:label \"Participant {participant_id}, Situation {situation_id}\" ;'\n",
    "        )\n",
    "        turtle_content.append(f\"    colearn:isSituationOf colearn:{participant_id} ;\")\n",
    "\n",
    "        list_of_type_and_literal = order_types(situation[\"situation_graph\"])\n",
    "        for type_, literal in list_of_type_and_literal:\n",
    "            turtle_content.append(type_and_literal_to_turtle(type_, literal))\n",
    "\n",
    "        if is_human_action and is_robot_action:\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:hasHumanAction colearn:{participant_id}_{situation_id}_h00 ;\"\n",
    "            )\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:hasRobotAction colearn:{participant_id}_{situation_id}_r00 .\\n\"\n",
    "            )\n",
    "        elif is_human_action and not is_robot_action:\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:hasHumanAction colearn:{participant_id}_{situation_id}_h00 .\\n\"\n",
    "            )\n",
    "        elif not is_human_action and is_robot_action:\n",
    "            turtle_content.append(\n",
    "                f\"    colearn:hasRobotAction colearn:{participant_id}_{situation_id}_r00 .\\n\"\n",
    "            )\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if is_human_action:\n",
    "            content_human = add_human_or_robot_action_to_turtle(\n",
    "                situation[\"human_action_graph\"],\n",
    "                participant_id,\n",
    "                situation_id,\n",
    "                \"Human\",\n",
    "            )\n",
    "            turtle_content.extend(content_human)\n",
    "\n",
    "        if is_robot_action:\n",
    "            content_robot = add_human_or_robot_action_to_turtle(\n",
    "                situation[\"robot_action_graph\"],\n",
    "                participant_id,\n",
    "                situation_id,\n",
    "                \"Robot\",\n",
    "            )\n",
    "            turtle_content.extend(content_robot)\n",
    "\n",
    "    return turtle_content\n",
    "\n",
    "\n",
    "def save_turtle_file(filename: str, content: List[str]):\n",
    "    \"\"\"Save the Turtle content to a file.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The filename\n",
    "        content (List[str]): The content to be saved\n",
    "\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for line in content:\n",
    "            f.write(line + \"\\n\")\n",
    "    print(f\"Turtle data saved to {filename}\")\n",
    "\n",
    "\n",
    "for participant_id, list_of_situations in data.items():\n",
    "    # Generate Turtle content from data\n",
    "    turtle_content = create_turtle(participant_id, list_of_situations)\n",
    "\n",
    "    # Save to a Turtle file\n",
    "    save_turtle_file(f\"./data/{participant_id}.ttl\", turtle_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
