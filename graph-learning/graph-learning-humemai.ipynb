{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This graph learning treats every graph (CP) to be an episodic memory of the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn the raw data into RDF-data\n",
    "\n",
    "I also did ontology engineering, which is saved at [`ontology-humemai.ttl`](./ontology-humemai.ttl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/humemai/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "def is_list_of_lists_empty(list_of_lists):\n",
    "    return all(not sublist for sublist in list_of_lists)\n",
    "\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "from rdflib import URIRef, Namespace\n",
    "from humemai import MemorySystem\n",
    "from rdflib import RDF, XSD, BNode, Graph, Literal, Namespace, URIRef\n",
    "\n",
    "with open(\"./raw-data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "# Turn off debug logging\n",
    "logging.getLogger(\"humemai\").setLevel(logging.WARNING)\n",
    "\n",
    "humemai = Namespace(\"https://humem.ai/ontology#\")\n",
    "co_learning = Namespace(\"https://co_learning#\")\n",
    "\n",
    "memory_system = MemorySystem()\n",
    "memory_system.memory.graph.bind(\"co_learning\", co_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treat all the CPs as events and save them as episodic memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 211/211 [00:01<00:00, 203.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for data_point in tqdm(data):\n",
    "    # declare event\n",
    "\n",
    "    event = URIRef(co_learning + f\"CP{str(data_point['cp_num']).zfill(3)}\")\n",
    "    event_properties = {\n",
    "        co_learning.hasCPNum: Literal(data_point[\"cp_num\"]),\n",
    "        co_learning.hasParticipantNumber: Literal(data_point[\"participant\"]),\n",
    "        co_learning.hasCPLabel: Literal(data_point[\"cp_name\"]),\n",
    "        co_learning.hasTicksLasted: Literal(data_point[\"ticks_lasted\"]),\n",
    "        co_learning.hasRoundNumber: Literal(data_point[\"round_num\"]),\n",
    "        co_learning.hasTimeStammp: Literal(data_point[\"timestamp\"]),\n",
    "        co_learning.hasUnixTimeStamp: Literal(data_point[\"unix_timestamp\"]),\n",
    "        co_learning.hasRemainingTime: Literal(data_point[\"remaining_time\"]),\n",
    "        co_learning.hasRemainingRocks: Literal(data_point[\"remaining_rocks\"]),\n",
    "        co_learning.hasVictimHarm: Literal(data_point[\"victim_harm\"]),\n",
    "    }\n",
    "\n",
    "    # declare entities\n",
    "\n",
    "    robot = co_learning.USAR_bot\n",
    "\n",
    "    location = Literal(\"USAR\")\n",
    "    memory_system.memory.add_episodic_memory(\n",
    "        triples=[(robot, RDF.type, co_learning.Robot)],\n",
    "        qualifiers={\n",
    "            humemai.eventTime: Literal(data_point[\"timestamp\"], datatype=XSD.dateTime),\n",
    "            humemai.location: location,\n",
    "            humemai.event: event,\n",
    "        },\n",
    "        event_properties=event_properties,\n",
    "    )\n",
    "\n",
    "    participant = URIRef(co_learning + f\"P{data_point['participant']}\")\n",
    "    memory_system.memory.add_episodic_memory(\n",
    "        triples=[(participant, RDF.type, co_learning.Participant)],\n",
    "        qualifiers={\n",
    "            humemai.eventTime: Literal(data_point[\"timestamp\"], datatype=XSD.dateTime),\n",
    "            humemai.location: location,\n",
    "            humemai.event: event,\n",
    "        },\n",
    "        event_properties=event_properties,\n",
    "    )\n",
    "\n",
    "    if not is_list_of_lists_empty(data_point[\"situation\"]):\n",
    "\n",
    "        situation_ = [\n",
    "            dict(t)\n",
    "            for t in {\n",
    "                tuple(d.items())\n",
    "                for d in [s_ for s in data_point[\"situation\"] for s_ in s]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        suffix = str(data_point[\"cp_num\"]).zfill(3)\n",
    "        situation = URIRef(co_learning + f\"Situation{suffix}\")\n",
    "\n",
    "        memory_system.memory.add_episodic_memory(\n",
    "            triples=[(situation, RDF.type, co_learning.Situation)],\n",
    "            qualifiers={\n",
    "                humemai.eventTime: Literal(\n",
    "                    data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                ),\n",
    "                humemai.location: location,\n",
    "                humemai.event: event,\n",
    "            },\n",
    "            event_properties=event_properties,\n",
    "        )\n",
    "\n",
    "        for dict_ in situation_:\n",
    "            assert dict_.keys() == {\"type\", \"content\"}\n",
    "            if dict_[\"type\"] == \"actor\":\n",
    "                relation = co_learning.hasActor\n",
    "            elif dict_[\"type\"] == \"object\":\n",
    "                relation = co_learning.hasObject\n",
    "            elif dict_[\"type\"] == \"location\":\n",
    "                relation = co_learning.hasLocation\n",
    "            elif dict_[\"type\"] == \"action\":\n",
    "                relation = co_learning.hasAction\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown type: {dict_['type']}\")\n",
    "\n",
    "            memory_system.memory.add_episodic_memory(\n",
    "                triples=[(situation, relation, Literal(dict_[\"content\"]))],\n",
    "                qualifiers={\n",
    "                    humemai.eventTime: Literal(\n",
    "                        data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                    ),\n",
    "                    humemai.location: location,\n",
    "                    humemai.event: event,\n",
    "                },\n",
    "                event_properties=event_properties,\n",
    "            )\n",
    "\n",
    "    human_action_list = []\n",
    "    for idx, action_ in enumerate(data_point[\"HumanAction\"]):\n",
    "        if action_:\n",
    "            suffix = str(data_point[\"cp_num\"]).zfill(3) + \"_\" + str(idx).zfill(3)\n",
    "            human_action = URIRef(co_learning + f\"HumanAction{suffix}\")\n",
    "            human_action_list.append(human_action)\n",
    "\n",
    "            memory_system.memory.add_episodic_memory(\n",
    "                triples=[(human_action, RDF.type, co_learning.HumanAction)],\n",
    "                qualifiers={\n",
    "                    humemai.eventTime: Literal(\n",
    "                        data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                    ),\n",
    "                    humemai.location: location,\n",
    "                    humemai.event: event,\n",
    "                },\n",
    "                event_properties=event_properties,\n",
    "            )\n",
    "\n",
    "            for dict_ in action_:\n",
    "                assert dict_.keys() == {\"type\", \"content\"}\n",
    "                if dict_[\"type\"] == \"actor\":\n",
    "                    relation = co_learning.hasActor\n",
    "                elif dict_[\"type\"] == \"object\":\n",
    "                    relation = co_learning.hasObject\n",
    "                elif dict_[\"type\"] == \"location\":\n",
    "                    relation = co_learning.hasLocation\n",
    "                elif dict_[\"type\"] == \"action\":\n",
    "                    relation = co_learning.hasAction\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown type: {dict_['type']}\")\n",
    "\n",
    "                memory_system.memory.add_episodic_memory(\n",
    "                    triples=[(human_action, relation, Literal(dict_[\"content\"]))],\n",
    "                    qualifiers={\n",
    "                        humemai.eventTime: Literal(\n",
    "                            data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                        ),\n",
    "                        humemai.location: location,\n",
    "                        humemai.event: event,\n",
    "                    },\n",
    "                    event_properties=event_properties,\n",
    "                )\n",
    "\n",
    "    robot_action_list = []\n",
    "    for idx, action_ in enumerate(data_point[\"RobotAction\"]):\n",
    "        if action_:\n",
    "            suffix = str(data_point[\"cp_num\"]).zfill(3) + \"_\" + str(idx).zfill(3)\n",
    "            robot_action = URIRef(co_learning + f\"RobotAction{suffix}\")\n",
    "            robot_action_list.append(robot_action)\n",
    "\n",
    "            memory_system.memory.add_episodic_memory(\n",
    "                triples=[(robot_action, RDF.type, co_learning.RobotAction)],\n",
    "                qualifiers={\n",
    "                    humemai.eventTime: Literal(\n",
    "                        data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                    ),\n",
    "                    humemai.location: location,\n",
    "                    humemai.event: event,\n",
    "                },\n",
    "                event_properties=event_properties,\n",
    "            )\n",
    "\n",
    "            for dict_ in action_:\n",
    "                assert dict_.keys() == {\"type\", \"content\"}\n",
    "                if dict_[\"type\"] == \"actor\":\n",
    "                    relation = co_learning.hasActor\n",
    "                elif dict_[\"type\"] == \"object\":\n",
    "                    relation = co_learning.hasObject\n",
    "                elif dict_[\"type\"] == \"location\":\n",
    "                    relation = co_learning.hasLocation\n",
    "                elif dict_[\"type\"] == \"action\":\n",
    "                    relation = co_learning.hasAction\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown type: {dict_['type']}\")\n",
    "\n",
    "                memory_system.memory.add_episodic_memory(\n",
    "                    triples=[(robot_action, relation, Literal(dict_[\"content\"]))],\n",
    "                    qualifiers={\n",
    "                        humemai.eventTime: Literal(\n",
    "                            data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                        ),\n",
    "                        humemai.location: location,\n",
    "                        humemai.event: event,\n",
    "                    },\n",
    "                    event_properties=event_properties,\n",
    "                )\n",
    "\n",
    "    # add edges\n",
    "\n",
    "    for idx, action in enumerate(human_action_list):\n",
    "\n",
    "        if idx == 0:\n",
    "            memory_system.memory.add_episodic_memory(\n",
    "                triples=[(participant, co_learning.hasHumanAction, action)],\n",
    "                qualifiers={\n",
    "                    humemai.eventTime: Literal(\n",
    "                        data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                    ),\n",
    "                    humemai.location: location,\n",
    "                    humemai.event: event,\n",
    "                },\n",
    "                event_properties=event_properties,\n",
    "            )\n",
    "        else:\n",
    "            memory_system.memory.add_episodic_memory(\n",
    "                triples=[\n",
    "                    (human_action_list[idx - 1], co_learning.hasNextHumanAction, action)\n",
    "                ],\n",
    "                qualifiers={\n",
    "                    humemai.eventTime: Literal(\n",
    "                        data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                    ),\n",
    "                    humemai.location: location,\n",
    "                    humemai.event: event,\n",
    "                },\n",
    "                event_properties=event_properties,\n",
    "            )\n",
    "\n",
    "    for idx, action in enumerate(robot_action_list):\n",
    "\n",
    "        if idx == 0:\n",
    "            memory_system.memory.add_episodic_memory(\n",
    "                triples=[(robot, co_learning.hasRobotAction, action)],\n",
    "                qualifiers={\n",
    "                    humemai.eventTime: Literal(\n",
    "                        data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                    ),\n",
    "                    humemai.location: location,\n",
    "                    humemai.event: event,\n",
    "                },\n",
    "                event_properties=event_properties,\n",
    "            )\n",
    "        else:\n",
    "            memory_system.memory.add_episodic_memory(\n",
    "                triples=[\n",
    "                    (robot_action_list[idx - 1], co_learning.hasNextRobotAction, action)\n",
    "                ],\n",
    "                qualifiers={\n",
    "                    humemai.eventTime: Literal(\n",
    "                        data_point[\"timestamp\"], datatype=XSD.dateTime\n",
    "                    ),\n",
    "                    humemai.location: location,\n",
    "                    humemai.event: event,\n",
    "                },\n",
    "                event_properties=event_properties,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_system.memory.save_to_ttl(\"co_learning.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38555"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_system.memory.get_raw_triple_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_system.memory.get_event_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3664"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_system.memory.get_memory_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3258"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_system.memory.get_main_triple_count_except_event()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "co-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
